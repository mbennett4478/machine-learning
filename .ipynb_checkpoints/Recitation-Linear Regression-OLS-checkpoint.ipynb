{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression - Ordinary Least Squares (OLS) Method \n",
    "\n",
    "We will perform linear regression using\n",
    "- Scikit Learn's OLS model\n",
    "- Manually coded OLS method\n",
    "\n",
    "\n",
    "The sklearn OLS implementation code is given in this notebook. You will have to implement the OLS method manually on the given dataset (OLS_Data.csv).\n",
    "\n",
    "\n",
    "### OLS\n",
    "\n",
    "OLS is a type of linear least squares method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being predicted) in the given dataset and those predicted by the linear function.\n",
    "\n",
    "OLS finds the optimal parameters by computing a closed-form solution for the **Normal equation**.\n",
    "\n",
    "URL: https://scikit-learn.org/stable/modules/linear_model.html#linear-model\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We will use a dataset (OLS_Data.csv) containing 14 variables (14 dimensional feature)\n",
    "\n",
    "Input variables:\n",
    "X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14\n",
    "\n",
    "Output variable: \n",
    "y\n",
    "\n",
    "### Note:\n",
    "This dataset might have colinearity in the input variables resulting into the singularity problem. It might cause the OLS method not working. You may need to fix the singularity problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: OLS Linear Regression Using Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "First load the data and explore the feature names, target names, etc.\n",
    "\n",
    "Download the \"OLS_Data.csv\" file to load data from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the csv file as a Pandas DataFrame object denoted as \"df\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Check of the Data\n",
    "\n",
    "Let’s take a look at the top five rows using the DataFrame’s head() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the Data\n",
    "\n",
    "DataFrame’s info() method is useful to get a quick description of the data, in particular the total number of rows, and each attribute’s type and number of non-null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Matrix: Feature Correlations\n",
    "\n",
    "Check if the data matrix has colinearity (1 or close to 1) in its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Separate Feature Set (Data Matrix X) and Target (1D Vector y)\n",
    "\n",
    "Create a data matrix (X) that contains all features and a 1D target vector (y) containing the target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data matrix X\n",
    "\n",
    "\n",
    "# target vector y\n",
    "\n",
    "\n",
    "#print(X.shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale The Features\n",
    "\n",
    "We should ensure that all features have a similar scale. Otherwise optimization algorithms (e.g., Gradient Descent based algorithms) will take much longer time to converge.\n",
    "\n",
    "Also, regularization techniques are sensitive to the scale of data. Thus, we must scale the features before applying regularization.\n",
    "\n",
    "Use sklearns StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Test Dataset\n",
    "\n",
    "Create train and test data (80% & 20%) by usinf sklearn's train_test_split function\n",
    "\n",
    "It should return the following 4 matrices.\n",
    "X_train\n",
    "y_train\n",
    "X_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Models\n",
    "\n",
    "We will use the following linear regression models.\n",
    "\n",
    "- Ordinary least squares (OLS) Linear Regression (by solving the Normal Equation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "We will use two evaluation metrics.\n",
    "\n",
    "- Mean Squared Error (MSE)\n",
    "- Coefficient of Determination ($R^2$ or $r^2$)\n",
    "\n",
    "\n",
    "### Note on $R^2$:\n",
    "R-squared is a statistical measure of how close the data are to the fitted regression line. \n",
    "\n",
    "R-squared measures the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "$R^2 = \\frac{Explained Variation}{Total Variation}$\n",
    "\n",
    "R-squared is always between 0 and 100%:\n",
    "\n",
    "- 0% indicates that the model explains none of the variability of the response data around its mean.\n",
    "- 100% indicates that the model explains all the variability of the response data around its mean.\n",
    "\n",
    "\n",
    "#### <font color=red>In general, the higher the R-squared, the better the model fits your data.</font>\n",
    "\n",
    "\n",
    "#### Compute $R^2$ using the sklearn:\n",
    "\n",
    "- The \"r2_score\" function from sklearn.metrics\n",
    "\n",
    "#### Compute MSE using the sklearn:\n",
    "\n",
    "- The \"mean_squared_error\" function from sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Ordinary Least Squares (OLS) Linear Regression (by solving the Normal Equation)\n",
    "\n",
    "\n",
    "#### Sklearn's OLS model implementation code is given for you to review.\n",
    "\n",
    "Then, you will have to manually code the OLS method.\n",
    "\n",
    "\n",
    "#### <font color=red>The MSE and $r^2$ error values from your manually coded OLS method must match with sklearn LinearRegressor's obtained values.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sklearn OLS linear regression object\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# The intercept\n",
    "print(\"Intercept: \\n\", lin_reg.intercept_)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", lin_reg.coef_)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted = lin_reg.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted))\n",
    "\n",
    "\n",
    "# To compute \n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % lin_reg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Sklearn OLS Model Using Test Data \n",
    "\n",
    "We evaluate the trained model on the test data.\n",
    "\n",
    "The goal is to see how the model performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction \n",
    "y_test_predicted = lin_reg.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Coded OLS Solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually code the OLS Method for Linear Regression\n",
    "\n",
    "\n",
    "# Add a bias term with the feature vectors to create a new data matrix \"X_train_bias\"\n",
    "\n",
    "\n",
    "\n",
    "# Print the determinant of the dot product of the transpose of X_train_bias and X_train_bias\n",
    "print(\"\\nDeterminant of (X_train_bias^T.X_train_bias): \")\n",
    "\n",
    "\n",
    "# Computes the dot product of the transpose of X_train_bias with itself\n",
    "#  Denote the product as \"z\"\n",
    "\n",
    "\n",
    "\n",
    "# Closed form (OLS) solution for weight vector w \n",
    "\n",
    "\n",
    "print(\"\\nThe weight vector:\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "# Make prediction using the X_train_bias data matrix\n",
    "# The predicted target vector should be named as \"y_train_predicted\"\n",
    "\n",
    "\n",
    "# Compute the MSE\n",
    "print(\"Mean squared error:\")\n",
    "\n",
    "\n",
    "# Compute the r^2 score\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation on the Performance of the Manually Coded OLS Solution\n",
    "\n",
    "You might get the **Singularity matrix** error.\n",
    "\n",
    "The determinant of the $X_{bias}^T.X_{bias}$ should be 0.\n",
    "\n",
    "There must be colinearity in the columns of the data matrix X.\n",
    "\n",
    "Find which columns are coliner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying OLS Method on Data Matrix With Colinearity in Columns\n",
    "\n",
    "Solve the singularity problem can by adding small positive numbers on the diagonal of the $X_{bias}^T.X_{bias}$ matrix.\n",
    "\n",
    "This regularization technique is known as **Ridge Regression**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian (Regularized) OLS Method for Linear Regression: Ridge Regression\n",
    "\n",
    "\n",
    "\n",
    "# Add a bias term with the feature vectors to create a new data matrix \"X_train_bias\"\n",
    "\n",
    "\n",
    "\n",
    "# Print the determinant of the dot product of the transpose of X_train_bias and X_train_bias\n",
    "print(\"\\nDeterminant of (X_train_bias^T.X_train_bias): \")\n",
    "\n",
    "\n",
    "# Computes the dot product of the transpose of X_train_bias with itself\n",
    "#  Denote the product as \"z\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n-------- Fixing the Singularity of (X_bias^T).X_bias ------------\")\n",
    "\n",
    "# Create a diagonal matrix that has the dimension of z; name the matrix as \"diagonal\"\n",
    "\n",
    "\n",
    "# Add small positive non-zero numbers on the diagonal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Closed form (OLS) solution for weight vector w \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nThe weight vector:\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "# Make prediction using the X_train_bias data matrix\n",
    "# The predicted target vector should be named as \"y_train_predicted\"\n",
    "\n",
    "\n",
    "# Compute the MSE\n",
    "print(\"Mean squared error:\")\n",
    "\n",
    "\n",
    "# Compute the r^2 score\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model Using Test Data - OLS Linear Regression\n",
    "\n",
    "We evaluate the trained model on the test data.\n",
    "\n",
    "Compute the MSE and $r^2$ score using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Understanding the Singularity Issue and its Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Why do you think the singularity matrix error occur while using OLS method on the “OLS_Data.csv” dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) To fix the singularity problem of the $X_{bias}^T.X_{bias}$ matrix what non-zero positive number did you add on its diagonal?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Add 100000 on the diagonal of the $X_{bias}^T.X_{bias}$ matrix and report the $MSE$ and the $r^2$ values for the training data set. Explain these results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) After adding 100000 on the diagonal of the $X_{bias}^T.X_{bias}$ matrix what change did you notice in the weights of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
