{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier - Text Classification - Multinomial & Bernoulli\n",
    "\n",
    "In this notebook you will apply the Naive Bayes algorithms for text classification.\n",
    "\n",
    "Your tasks are marked with task numbers (e.g., Task 1). To get full credit you need to complete **ALL** tasks.\n",
    "\n",
    "\n",
    "\n",
    "### Dataset: The 20 Newsgroups data set\n",
    "\n",
    "\n",
    "The 20 newsgroups dataset comprises around 20,000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering. The split between the train and test set is based upon a messages posted before and after a specific date.\n",
    "\n",
    "Following is a list of the 20 newsgroups, partitioned (more or less) according to subject matter:\n",
    "\n",
    "- alt.atheism\n",
    "- comp.graphics\n",
    "- comp.os.ms-windows.misc\n",
    "- comp.sys.ibm.pc.hardware\n",
    "- comp.sys.mac.hardware\n",
    "- comp.windows.x\n",
    "- misc.forsale\n",
    "- rec.autos\n",
    "- rec.motorcycles\n",
    "- rec.sport.baseball\n",
    "- rec.sport.hockey\n",
    "- sci.crypt\n",
    "- sci.electronics\n",
    "- sci.med\n",
    "- sci.space\n",
    "- soc.religion.christian\n",
    "- talk.politics.guns\n",
    "- talk.politics.mideast\n",
    "- talk.politics.misc\n",
    "- talk.religion.misc\n",
    "\n",
    "\n",
    "You will normalize the documents, perform preprocessing and vectorize the features. Since the features are categorical, you will implement two different naive Bayes classifiers using Scikit-Learn. \n",
    "- Categorical features (binary valued) are modeled using the Multivariate Bernoulli distrubition \n",
    "- Categorical features (multi-valued) are modeled using the Multinomial distrubition \n",
    "\n",
    "\n",
    "## Steps for Classification:\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "2. Feature Extraction\n",
    "   - a. Text Normalization (Stemming & Lemmatization)\n",
    "   - b. Text Preprocessing (Tokenization, removing stop words, etc.)\n",
    "   - c. Vectorization of the features\n",
    "3. Model Selection by Hyperparameter Tuning\n",
    "4. Train the Optimal Model\n",
    "5. Analyzing Model Performance\n",
    "6. Evaluate the Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mbennett/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mbennett/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "You will work on a partial dataset with only 4 categories out of the 20 available in the dataset:\n",
    "- alt.atheism\n",
    "- soc.religion.christian\n",
    "- comp.graphics\n",
    "- sci.med\n",
    "\n",
    "\n",
    "The samples are shuffled randomly. This is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "X_train = train_data.data\n",
    "y_train = train_data.target\n",
    "\n",
    "\n",
    "test_data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "X_test = test_data.data\n",
    "y_test = test_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 1. Exploratory Data Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Check of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Names:  ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
      "\n",
      "Number of Training Examples:  2257\n",
      "Number of Training Labels:  2257\n",
      "Number of Test Examples:  1502\n",
      "Number of Test Labels:  1502\n",
      "\n",
      "Print a Random Document:\n",
      "\n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Target Names: \", train_data.target_names)\n",
    "\n",
    "print(\"\\nNumber of Training Examples: \", len(X_train))\n",
    "print(\"Number of Training Labels: \", len(y_train))\n",
    "\n",
    "print(\"Number of Test Examples: \",len(X_test))\n",
    "print(\"Number of Test Labels: \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"\\nPrint a Random Document:\\n\")\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution\n",
    "\n",
    "#### Task 1: Compute class distribution in the following block (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    599\n",
      "2    594\n",
      "1    584\n",
      "0    480\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train)\n",
    "label_values = df.iloc[:, -1].value_counts()\n",
    "print(label_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Class Distribution\n",
    "\n",
    "\n",
    "#### Task 2: Generate visualization of the class distribution in the following block (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = df.iloc[:,-1].value_counts()\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.barplot(label_counts.index, label_counts.values, alpha = 0.9)\n",
    "\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.xlabel('Labels', fontsize =12)\n",
    "plt.ylabel('Counts', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 2. Feature Extraction </font>\n",
    "\n",
    "## a) Text Normalization by Lemmatization\n",
    "\n",
    "Stemming and Lemmatization are Text Normalization (or sometimes called Word Normalization) techniques in the field of Natural Language Processing that are used to prepare text, words, and documents for further processing.\n",
    "\n",
    "\n",
    "#### Task 3: Lemmatize the training data. You may stem it as well, if it improves the classification accuracy. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       From : sd345 @ city.ac.uk ( Michael Collier ) ...\n",
      "1       From : ani @ ms.uky.edu ( Aniruddha B. Deglurk...\n",
      "2       From : djohnson @ cs.ucsd.edu ( Darin Johnson ...\n",
      "3       From : s0612596 @ let.rug.nl ( M.M . Zwart ) S...\n",
      "4       From : stanly @ grok11.columbiasc.ncr.com ( st...\n",
      "5       From : vbv @ lor.eeap.cwru.edu ( Virgilio ( De...\n",
      "6       From : jodfishe @ silver.ucs.indiana.edu ( jos...\n",
      "7       From : aldridge @ netcom.com ( Jacquelin Aldri...\n",
      "8       From : geb @ cs.pitt.edu ( Gordon Banks ) Subj...\n",
      "9       From : libman @ hsc.usc.edu ( Marlena Libman )...\n",
      "10      From : anasaz ! karl @ anasazi.com ( Karl Duss...\n",
      "11      From : amjad @ eng.umd.edu ( Amjad A Soomro ) ...\n",
      "12      From : I3150101 @ dbstu1.rz.tu-bs.de ( Benedik...\n",
      "13      Subject : So what is Maddi ? From : madhaus @ ...\n",
      "14      From : sloan @ cis.uab.edu ( Kenneth Sloan ) S...\n",
      "15      From : Mike_Peredo @ mindlink.bc.ca ( Mike Per...\n",
      "16      From : texx @ ossi.com ( Robert `` Texx '' Woo...\n",
      "17      Organization : Penn State University From : < ...\n",
      "18      From : tom_milligan @ rainbow.mentorg.com Subj...\n",
      "19      Subject : Re : Do n't more innocent die withou...\n",
      "20      From : dotsonm @ dmapub.dma.org ( Mark Dotson ...\n",
      "21      From : gmiller @ worldbank.org ( Gene C. Mille...\n",
      "22      From : jkellett @ netcom.com ( Joe Kellett ) S...\n",
      "23      From : d91-hes @ tekn.hj.se ( STEFAN HERMANSSO...\n",
      "24      From : mjw19 @ cl.cam.ac.uk ( M.J. Williams ) ...\n",
      "25      From : dstampe @ psych.toronto.edu ( Dave Stam...\n",
      "26      From : christian @ geneva.rutgers.edu Subject ...\n",
      "27      From : ruthless @ panix.com ( Ruth Ditucci ) S...\n",
      "28      From : rind @ enterprise.bih.harvard.edu ( Dav...\n",
      "29      From : spp @ zabriskie.berkeley.edu ( Steve Po...\n",
      "                              ...                        \n",
      "2227    From : halat @ pooh.bears ( Jim Halat ) Subjec...\n",
      "2228    From : bil @ okcforum.osrhe.edu ( Bill Conner ...\n",
      "2229    From : jcj @ tellabs.com ( jcj ) Subject : Re ...\n",
      "2230    From : news @ cbnewsk.att.com Subject : Re : B...\n",
      "2231    Subject : Re : Feminism and Islam , again From...\n",
      "2232    From : lipman @ oasys.dt.navy.mil ( Robert Lip...\n",
      "2233    From : kmr4 @ po.CWRU.edu ( Keith M. Ryan ) Su...\n",
      "2234    From : David.Rice @ ofa123.fidonet.org Subject...\n",
      "2235    From : dougb @ comm.mot.com ( Doug Bank ) Subj...\n",
      "2236    From : dkusswur @ falcon.depaul.edu ( Daniel C...\n",
      "2237    From : datepper @ phoenix.Princeton.EDU ( Davi...\n",
      "2238    From : jim.zisfein @ factory.com ( Jim Zisfein...\n",
      "2239    From : paj @ uk.co.gec-mrc ( Paul Johnson ) Su...\n",
      "2240    From : balick @ nynexst.com ( Daphne Balick ) ...\n",
      "2241    From : dl @ aeg.dsto.gov.au ( David Silver ) S...\n",
      "2242    From : Sean McMains < mcmains @ unt.edu > Subj...\n",
      "2243    From : turpin @ cs.utexas.edu ( Russell Turpin...\n",
      "2244    From : jim.zisfein @ factory.com ( Jim Zisfein...\n",
      "2245    From : nyeda @ cnsvax.uwec.edu ( David Nye ) S...\n",
      "2246    From : lmvec @ westminster.ac.uk ( William Har...\n",
      "2247    From : daniel @ math.ufl.edu ( TV 's Big Deale...\n",
      "2248    From : `` danny hawrysio '' < danny.hawrysio @...\n",
      "2249    From : shellgate ! llo @ uu4.psi.com ( Larry L...\n",
      "2250    From : ingles @ engin.umich.edu ( Ray Ingles )...\n",
      "2251    From : Mark-Tarbell @ suite.com Subject : Amni...\n",
      "2252    From : roos @ Operoni.Helsinki.FI ( Christophe...\n",
      "2253    From : mhollowa @ ic.sunysb.edu ( Michael Holl...\n",
      "2254    From : sasghm @ theseus.unx.sas.com ( Gary Mer...\n",
      "2255    From : Dan Wallach < dwallach @ cs.berkeley.ed...\n",
      "2256    From : dyer @ spdcc.com ( Steve Dyer ) Subject...\n",
      "Name: text_lemmatized, Length: 2257, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df = pd.DataFrame(X_train)\n",
    "df = df.rename(columns={0: 'text'})\n",
    "df['text_lemmatized'] = ''\n",
    "df['text_stemmer'] = ''\n",
    "df['text_lemmatized'] = df['text'].map(lambda text: ' '.join(lemmatizer.lemmatize(w) for w in nltk.word_tokenize(text)))\n",
    "print(df['text_lemmatized'])\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "df['text_stemmer'] = df['text'].map(lambda text: ' '.join(stemmer.stem(w) for w in nltk.word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 2. Feature Extraction </font>\n",
    "\n",
    "## b) Text Preprocessing & c) Feature Vectorization\n",
    "\n",
    "We can combine text preprocessing, feature vectorization and model training using the sklearn Pipeline object. This Pipeline object can be used for model selection and for training the optimal model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n",
      "Type of the occurance count matrix (should be sparse): \n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1502, 35788)\n",
      "(2257, 35788)\n",
      "(1502, 35788)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "print(\"Type of the occurance count matrix (should be sparse): \")\n",
    "print(type(X_train_counts))\n",
    "\n",
    "\n",
    "# Transform documents to document-term matrix.\n",
    "# Extract token counts out of raw text documents using the vocabulary fitted with fit \n",
    "# or the one provided to the constructor.\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "print(X_test_counts.shape)\n",
    "\n",
    "\n",
    "# TF-IDF\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue> 3. Model Selection </font>\n",
    "\n",
    "\n",
    "There are no hyperparameters in a NB model except the Laplace smoothing parameter alpha.\n",
    "\n",
    "However, there are multiple hyperparameters for the CountVectorizer() and TfidfTransformer(). We need to select the best model based on the optimal values of these hyperparameters. This process is called hyper-parameter tuning.\n",
    "\n",
    "For hyperparameter tuning, we will build a compund classifier using the sklearn Pipeline class. It will combine the CountVectorizer(), TfidfTransformer() and MultinomialNB() objects and will create a single object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Pipeline for Hyperparameter Tuning\n",
    "\n",
    "\n",
    "#### Task 4: Build a Pipeline object by combining CountVectorizer() and MultinomialNB() (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_multinomialNB = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "#### Task 5: Perform hyperparamer tuning for the following hyperparameters: (5 pts)\n",
    "- CountVectorizer()\n",
    "         -- ngram_range\n",
    "         -- stop_words\n",
    "- MultinomialNB()\n",
    "        -- alpha\n",
    "        \n",
    "## **<font color=red size=5>Important:</font>**\n",
    "\n",
    "The GridSearchCV takes an argument to define the scoring metric (performance measure). \n",
    "\n",
    "See the list of possible scoring functions:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "For multiclass classification, we may use \"f1_micro\" scoring function. The f1_micro function is the average of the F1 score of each class with weighting depending on the average parameter.\n",
    "\n",
    "The macro-average (\"f1_macro\") will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average (\"f1_micro\") will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes).\n",
    "\n",
    "In the binary classification, \"f1\" score function can be used. We may also use the precision_score, recall_score, roc_auc_score functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.980948\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "clf__alpha: 0.1\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: 'english'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__stop_words': ['english', None],\n",
    "    'clf__alpha': [0.1, 1.0, 1.5, 1.8]\n",
    "}\n",
    "\n",
    "clf_multinomial_cv = GridSearchCV(text_clf_multinomialNB, param_grid, scoring='f1_micro', cv=5)\n",
    "\n",
    "clf_multinomial_cv = clf_multinomial_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\nBest Score: %f\" % clf_multinomial_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, clf_multinomial_cv.best_params_[param_name]))\n",
    "    \n",
    "%%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 4. Train the Optimal Multinomial Model </font>\n",
    "\n",
    "#### Task 6: Using the optimal hyperparameter values, create the optimal model. Then, fit the model. (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer() and MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "multinomialNB_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 6. Evaluate the Model on Test Data </font>\n",
    "\n",
    "#### Task 7:  Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report\n",
    "\n",
    "\n",
    "### Note: For multi-class classification, set the \"average\" attribute to \"micro\" for the following functions:\n",
    "- precision_score\n",
    "- recall_score\n",
    "- f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Confusion Matrix:\n",
      "[[299   4   5  11]\n",
      " [  5 371  11   2]\n",
      " [  7  18 362   9]\n",
      " [  4   3   6 385]]\n",
      "\n",
      "Test Precision: 0.9434087882822902\n",
      "\n",
      "Test Recall: 0.9434087882822902\n",
      "\n",
      "Test F1 Score: 0.9434087882822902\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.94      0.94       319\n",
      "soc.religion.christian       0.94      0.95      0.95       389\n",
      "         comp.graphics       0.94      0.91      0.93       396\n",
      "               sci.med       0.95      0.97      0.96       398\n",
      "\n",
      "             micro avg       0.94      0.94      0.94      1502\n",
      "             macro avg       0.94      0.94      0.94      1502\n",
      "          weighted avg       0.94      0.94      0.94      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = multinomialNB_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest Precision:\", precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest Recall:\", recall_test)\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest F1 Score:\",f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multinomial NB: TF-IDF Model\n",
    "\n",
    "#### Task 8: Implement the Multinomial model using the TF-IDF feature vectors (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer(), TfidfTransformer() and MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        ...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_clf_tfidf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=False)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "multinomialNB_clf_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model on Test Data \n",
    "\n",
    "#### Task 9: Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Confusion Matrix:\n",
      "[[299   4   5  11]\n",
      " [  5 371  11   2]\n",
      " [  7  18 362   9]\n",
      " [  4   3   6 385]]\n",
      "\n",
      "Test Precision = 0.943409\n",
      "Test Recall = 0.943409\n",
      "Test F1 Score = 0.943409\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.94      0.94       319\n",
      "soc.religion.christian       0.94      0.95      0.95       389\n",
      "         comp.graphics       0.94      0.91      0.93       396\n",
      "               sci.med       0.95      0.97      0.96       398\n",
      "\n",
      "             micro avg       0.94      0.94      0.94      1502\n",
      "             macro avg       0.94      0.94      0.94      1502\n",
      "          weighted avg       0.94      0.94      0.94      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = multinomialNB_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average='micro') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon> Observation on Multinomial Model With TF-IDF Feature Vectors </font>\n",
    "\n",
    "We observe that both precision and recall decrease with TF-IDF feature vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multivariate Bernoulli NB\n",
    "\n",
    "#### Task 10: Implement the Multivariate Bernoulli Model (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer() and BernoulliNB()\n",
    "\n",
    "### <font color=red> Note: </font>\n",
    "The \"binary\" attribute of the CountVectorizer() object should be set to \"True\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_clf_tfidf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=True)),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "multinomialNB_clf_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model on Test Data \n",
    "\n",
    "\n",
    "#### Task 11: Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Confusion Matrix:\n",
      "[[299   4   5  11]\n",
      " [  5 371  11   2]\n",
      " [  7  18 362   9]\n",
      " [  4   3   6 385]]\n",
      "\n",
      "Test Precision = 0.943409\n",
      "Test Recall = 0.943409\n",
      "Test F1 Score = 0.943409\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.94      0.94       319\n",
      "soc.religion.christian       0.94      0.95      0.95       389\n",
      "         comp.graphics       0.94      0.91      0.93       396\n",
      "               sci.med       0.95      0.97      0.96       398\n",
      "\n",
      "             micro avg       0.94      0.94      0.94      1502\n",
      "             macro avg       0.94      0.94      0.94      1502\n",
      "          weighted avg       0.94      0.94      0.94      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = multinomialNB_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average='micro') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon> Observation on Multivariate Bernoulli Model </font>\n",
    "\n",
    "#### Task 12: Write a short account of your observation on the following aspects of your experimentation with 3 NB classifiers (10 pts):\n",
    "- Impact of data normalization technique (did you observe performance improvement with lemmatization and/or stemming)\n",
    "- Which classifier gave the best precision? Best recall? Best F1 Score? Explain their performance variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second and third methods resulted in the best Precision, Recall, and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
